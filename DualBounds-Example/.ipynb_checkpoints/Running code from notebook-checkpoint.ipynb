{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading config from config-rob-tests-BNPWL.json\n",
      "In run AL_step-ordered_90_rob_test_new_loge using config: {'state': 'AL', 'level': 'county', 'base': 'labeling', 'obj': 'LogEPWL', 'R': 90, 'dist_bounds': False, 'tlimit': 100000, 'fixing': False, 'contiguity': 'lcut', 'symmetry': 'default', 'extended': False, 'order': 'B_decreasing', 'heuristic': True, 'lp': False}."
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'obj_order'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-09cd3b7008a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mckey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mavailable_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mckey\u001b[0m \u001b[1;33m==\u001b[0m\u001b[1;34m'R'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mckey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mavailable_config\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mckey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m                 \u001b[0merrormessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Error: the config option\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mckey\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\":\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mckey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"is not known.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m                 \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merrormessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'obj_order'"
     ]
    }
   ],
   "source": [
    "# /###########################\n",
    "# Imports\n",
    "###########################  \n",
    "\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import date\n",
    "import math\n",
    "import networkx as nx\n",
    "import csv\n",
    "import time\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import hess\n",
    "import labeling\n",
    "import ordering\n",
    "import fixing\n",
    "import separation\n",
    "\n",
    "from gerrychain import Graph\n",
    "import geopandas as gpd\n",
    "\n",
    "\n",
    "################################################\n",
    "# Summarize computational results to csv file\n",
    "################################################ \n",
    "\n",
    "from csv import DictWriter\n",
    "def append_dict_as_row(file_name, dict_of_elem, field_names):\n",
    "    # Open file in append mode\n",
    "    with open(file_name, 'a+', newline='') as write_obj:\n",
    "        # Create a writer object from csv module\n",
    "        dict_writer = DictWriter(write_obj, fieldnames=field_names)\n",
    "        #dict_writer = DictWriter(write_obj, )\n",
    "        # Add dictionary as wor in the csv\n",
    "        dict_writer.writerow(dict_of_elem)\n",
    "        \n",
    "        \n",
    "################################################\n",
    "# Writes districting solution to json file\n",
    "################################################ \n",
    "\n",
    "def export_to_json(G, districts, filename):\n",
    "    with open(filename, 'w') as outfile:\n",
    "        soln = {}\n",
    "        soln['nodes'] = []\n",
    "        for j in range(len(districts)):\n",
    "            for i in districts[j]:\n",
    "                soln['nodes'].append({\n",
    "                        'name': G.nodes[i][\"NAME20\"],\n",
    "                        'index': i,\n",
    "                        'GEOID20': G.nodes[i]['GEOID20'],\n",
    "                        'GEOID': G.nodes[i]['GEOID'],\n",
    "                        'district': j\n",
    "                        })\n",
    "        json.dump(soln, outfile, indent=4)\n",
    "\n",
    "               \n",
    "\n",
    "################################################\n",
    "# Draws districts and saves to png file\n",
    "################################################ \n",
    "\n",
    "def export_to_png(G, df, districts, filename):\n",
    "    \n",
    "    assignment = [ -1 for u in G.nodes ]\n",
    "    \n",
    "    for j in range(len(districts)):\n",
    "        for i in districts[j]:\n",
    "            geoID = G.nodes[i][\"GEOID20\"]\n",
    "            for u in G.nodes:\n",
    "                if geoID == df['GEOID20'][u]:\n",
    "                    assignment[u] = j\n",
    "    \n",
    "    if min(assignment[v] for v in G.nodes) < 0:\n",
    "        print(\"Error: did not assign all nodes in district map png.\")\n",
    "    else:\n",
    "        df['assignment'] = assignment\n",
    "        my_fig = df.plot(column='assignment').get_figure()\n",
    "        RESIZE_FACTOR = 3\n",
    "        my_fig.set_size_inches(my_fig.get_size_inches()*RESIZE_FACTOR)\n",
    "        plt.axis('off')\n",
    "        my_fig.savefig(filename)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        dissolved = df.dissolve(by = 'assignment',aggfunc={'P0030004': 'sum', 'P0030001': 'sum'})\n",
    "        \n",
    "        plot_bvap(df,filename,'heatmap', overlay = True, gdf2 = dissolved)\n",
    "        plot_bvap(dissolved, filename)\n",
    "        \n",
    "\n",
    " \n",
    "        \n",
    "################################################\n",
    "# Draws max B set and saves to png file\n",
    "################################################ \n",
    "\n",
    "def export_B_to_png(G, df, B, filename):\n",
    "    \n",
    "    B_geoids = [ G.nodes[i][\"GEOID20\"] for i in B ]\n",
    "    df['B'] = [1 if df['GEOID20'][u] in B_geoids else 0 for u in G.nodes]\n",
    "        \n",
    "    my_fig = df.plot(column='B').get_figure()\n",
    "    RESIZE_FACTOR = 3\n",
    "    my_fig.set_size_inches(my_fig.get_size_inches()*RESIZE_FACTOR)\n",
    "    plt.axis('off')\n",
    "    my_fig.savefig(filename)\n",
    "\n",
    "    \n",
    "def plot_bvap(dissolved,filename, additional_file_name = '', overlay = False, gdf2 = 0):\n",
    "        dissolved['Representative'] = dissolved['geometry'].apply(lambda x: x.representative_point().coords[:])\n",
    "        dissolved['Representative'] = [coords[0] for coords in dissolved['Representative']]\n",
    "        dissolved = dissolved.rename(columns={'P0010001':'POP','P0010004':'BPOP',\n",
    "                                                  'P0030001':'VAP','P0030004':'BVAP', 'P0040002' : 'HVAP'})\n",
    "        dissolved['BVAP_ratio'] = dissolved['BVAP']/dissolved['VAP']\n",
    "        colormap ='BuPu'\n",
    "        \n",
    "        fig, ax = plt.subplots(1,1, figsize=(16,16))\n",
    "        \n",
    "        cbax = fig.add_axes([0.95, 0.3, 0.03, 0.39])   \n",
    "        cbax.set_title(\"BVAP Ratio\")\n",
    "        vmin = 0\n",
    "        vmax = 0.75\n",
    "        sm = plt.cm.ScalarMappable(cmap=colormap, \\\n",
    "                norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "    \n",
    "        sm._A = []\n",
    "    \n",
    "        fig.colorbar(sm, cax=cbax)#, format=\"%d\")\n",
    "    \n",
    "        ax.axis(\"off\")\n",
    "\n",
    "        dissolved.plot(column = 'BVAP_ratio', edgecolor='black', cmap=colormap, ax = ax, vmin = vmin, vmax = vmax, legend=False)\n",
    "        #dissolved.apply(lambda x: \n",
    "             #ax.annotate(text=x.NAME, xy=x.Representative, ha='center', color = 'r',  weight='bold', size = 14), axis=1);\n",
    "        \n",
    "        #dissolved.set_index('my_index', inplace=True)\n",
    "        dissolved.reset_index(inplace=True)\n",
    "        #dissolved.apply(lambda x: \n",
    "             #ax.annotate(text=str(x.name) +': '+ str(x.BVAP), xy=x.Representative, ha='center', color = 'r',  weight='bold', size = 14), axis=1);\n",
    "        \n",
    "        dissolved.apply(lambda x: \n",
    "             ax.annotate(text=str(x.name) +': '+ str(round(labeling.cdf_fun(x.BVAP_ratio),2)), xy=x.Representative, ha='center', color = 'r',  weight='bold', size = 14), axis=1);\n",
    "        ratios = list(dissolved['BVAP_ratio'])\n",
    "        \n",
    "        score = sum(labeling.cdf_fun(r) for r in ratios)\n",
    "        ax.set_title(f\"BVAP Score: {score}\")\n",
    "        if overlay:\n",
    "            gdf2.plot(ax=ax, edgecolor='blue', linewidth=2, facecolor='none')\n",
    "        plt.savefig(filename.split(\".\")[0] + '_BVAP' + additional_file_name + '.png', transparent=True)\n",
    "\n",
    "###########################\n",
    "# Hard-coded inputs\n",
    "###########################  \n",
    "\n",
    "state_codes = {\n",
    "    'WA': '53', 'DE': '10', 'WI': '55', 'WV': '54', 'HI': '15',\n",
    "    'FL': '12', 'WY': '56', 'NJ': '34', 'NM': '35', 'TX': '48',\n",
    "    'LA': '22', 'NC': '37', 'ND': '38', 'NE': '31', 'TN': '47', 'NY': '36',\n",
    "    'PA': '42', 'AK': '02', 'NV': '32', 'NH': '33', 'VA': '51', 'CO': '08',\n",
    "    'CA': '06', 'AL': '01', 'AR': '05', 'VT': '50', 'IL': '17', 'GA': '13',\n",
    "    'IN': '18', 'IA': '19', 'MA': '25', 'AZ': '04', 'ID': '16', 'CT': '09',\n",
    "    'ME': '23', 'MD': '24', 'OK': '40', 'OH': '39', 'UT': '49', 'MO': '29',\n",
    "    'MN': '27', 'MI': '26', 'RI': '44', 'KS': '20', 'MT': '30', 'MS': '28',\n",
    "    'SC': '45', 'KY': '21', 'OR': '41', 'SD': '46'\n",
    "}\n",
    "\n",
    "number_of_congressional_districts = {\n",
    "    'WA': 10, 'DE': 1, 'WI': 8, 'WV': 3, 'HI': 2,\n",
    "    'FL': 27, 'WY': 1, 'NJ': 12, 'NM': 3, 'TX': 36,\n",
    "    'LA': 6, 'NC': 13, 'ND': 1, 'NE': 3, 'TN': 9, 'NY': 27,\n",
    "    'PA': 18, 'AK': 1, 'NV': 4, 'NH': 2, 'VA': 11, 'CO': 7,\n",
    "    'CA': 53, 'AL': 7, 'AR': 4, 'VT': 1, 'IL': 18, 'GA': 14,\n",
    "    'IN': 9, 'IA': 4, 'MA': 9, 'AZ': 9, 'ID': 2, 'CT': 5,\n",
    "    'ME': 2, 'MD': 8, 'OK': 5, 'OH': 16, 'UT': 4, 'MO': 8,\n",
    "    'MN': 8, 'MI': 14, 'RI': 2, 'KS': 4, 'MT': 1, 'MS': 4,\n",
    "    'SC': 7, 'KY': 6, 'OR': 5, 'SD': 1\n",
    "}\n",
    "\n",
    "default_config = {\n",
    "    'state' : 'OK',\n",
    "    'level' : 'county',\n",
    "    'base' : 'labeling',\n",
    "    'obj' : 'step',\n",
    "    'R' : '10',\n",
    "    'tlimit' : 3600,\n",
    "    'dist_bounds' : False,\n",
    "    'fixing' : True,\n",
    "    'contiguity' : 'scf',\n",
    "    'symmetry' : 'orbitope',\n",
    "    'extended' : False,\n",
    "    'order' : 'B_decreasing',\n",
    "    'heuristic' : True,\n",
    "    'lp': True\n",
    "}\n",
    "\n",
    "available_config = {\n",
    "    'state' : { key for key in state_codes.keys() },\n",
    "    'level' : {'county', 'tract'},\n",
    "    'base' : {'hess', 'labeling'},\n",
    "    'obj' : {\"LogEPWL\", \"BNPWL\", \"perimin\", \"perimax\", \"compact\", \"step-hvap\", \"step-alt\", \"DiscretePWL\", \"PWL\", \"step-exp\", \"step-max\", \"cumulative\", \"conv\", \"PWL_approx\", \"conv_approx\", \"partisan_dem\",\"partisan_dem_order\", \"partisan_rep\",\"competetive\",\"step-ordered\"},\n",
    "    'R' : int,\n",
    "    'fixing' : {True, False},\n",
    "    'contiguity' : {'none', 'lcut', 'scf', 'shir'},\n",
    "    'symmetry' : {'default', 'aggressive', 'orbitope'},  # orbitope only for labeling\n",
    "    'extended' : {True, False},\n",
    "    'order' : {'none', 'decreasing', 'B_decreasing'},\n",
    "    'heuristic' : {True, False},\n",
    "    'lp' : {True, False}, # solve and report root LP bound? (in addition to MIP)\n",
    "    'obj_order' : {'D20_max', 'D16_max','T20_max','T16_max','D20_min','D16_min','T20_min','T16_min'},\n",
    "    'index':{0,1,2,3,4,5,6,7,8,9,10,11,12,13,14}\n",
    "}\n",
    "\n",
    "\n",
    "###############################################\n",
    "# Read configs/inputs and set parameters\n",
    "############################################### \n",
    "\n",
    "# read configs file and load into a Python dictionary\n",
    "\n",
    "# if len(sys.argv)>1:\n",
    "#     # name your own config file in command line, like this: \n",
    "#     #       python main.py usethisconfig.json\n",
    "#     # to keep logs of the experiments, redirect to file, like this:\n",
    "#     #       python main.py usethisconfig.json 1>>log_file.txt 2>>error_file.txt\n",
    "#     config_filename = sys.argv[1] \n",
    "# else:\n",
    "\n",
    "config_filename = 'config-rob-tests.json' # default\n",
    "config_filename = 'config-rob-tests-BNPWL.json' # default\n",
    "#config_filename = 'config-rob-tests-DEM.json' # default\n",
    "#config_filename = 'config-political-bounds_5min.json'\n",
    "    \n",
    "print(\"Reading config from\",config_filename)    \n",
    "config_filename_wo_extension = config_filename.rsplit('.',1)[0]\n",
    "configs_file = open(config_filename,'r')\n",
    "batch_configs = json.load(configs_file)\n",
    "configs_file.close()\n",
    "\n",
    "# create directory for results\n",
    "path = os.path.join(\"..\", \"results_for_\" + config_filename_wo_extension) \n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path) \n",
    "\n",
    "# print results to csv file\n",
    "today = date.today()\n",
    "today_string = today.strftime(\"%Y_%b_%d\") # Year_Month_Day, like 2019_Sept_16\n",
    "results_filename = \"../results_for_\" + config_filename_wo_extension + \"/results_\" + config_filename_wo_extension + \"_\" + today_string + \".csv\" \n",
    "\n",
    "# prepare csv file by writing column headers\n",
    "with open(results_filename,'w',newline='') as csvfile:   \n",
    "    my_fieldnames = ['run','state','level','base','obj','R','tlimit','fixing','contiguity','symmetry','extended','order','heuristic','lp'] # configs\n",
    "    my_fieldnames += ['k','L','U','n','m'] # params\n",
    "    my_fieldnames += ['heur_obj', 'heur_time', 'heur_iter'] # heuristic info\n",
    "    my_fieldnames += ['B_q', 'B_size', 'B_time', 'B_timelimit'] # max B info\n",
    "    my_fieldnames += ['DFixings', 'LFixings', 'UFixings_X', 'UFixings_R', 'ZFixings'] # fixing info\n",
    "    my_fieldnames += ['LP_obj', 'LP_time'] # root LP info\n",
    "    my_fieldnames += ['MIP_obj','MIP_bound','MIP_time', 'MIP_timelimit', 'MIP_status', 'MIP_nodes', 'callbacks', 'lazy_cuts', 'connected'] # MIP info\n",
    "    my_fieldnames += ['dist_bounds']\n",
    "    my_fieldnames += ['expected_error','maximum_error']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames = my_fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    \n",
    "############################################################\n",
    "# Run experiments for each config in batch_config file\n",
    "############################################################\n",
    "\n",
    "for key in batch_configs.keys(): \n",
    "      \n",
    "    # get config and check for errors\n",
    "    config = batch_configs[key]\n",
    "    print(\"In run\",key,\"using config:\",config,end='.')\n",
    "    for ckey in available_config.keys():\n",
    "        if not ckey =='R':\n",
    "            if config[ckey] not in available_config[ckey]:\n",
    "                errormessage = \"Error: the config option\"+ckey+\":\"+config[ckey]+\"is not known.\"\n",
    "                sys.exit(errormessage)\n",
    "    print(\"\")\n",
    "    \n",
    "    # fill-in unspecified configs using default values\n",
    "    for ckey in available_config.keys():\n",
    "        if ckey not in config.keys():\n",
    "            print(\"Using default value\",ckey,\"=\",default_config[ckey],\"since no option was selected.\")\n",
    "            config[ckey] = default_config[ckey]\n",
    "        \n",
    "    # initialize dictionary to store this run's results\n",
    "    result = config\n",
    "    result['run'] = key            \n",
    "                   \n",
    "    # read input data\n",
    "    state = config['state']\n",
    "    code = state_codes[state]\n",
    "    level = config['level']\n",
    "    print(\"../data/\"+level+\"/dual_graphs/\"+level+code+\".json\")\n",
    "    G = Graph.from_json(\"../data/\"+level+\"/dual_graphs/\"+level+code+\".json\")\n",
    "    print(G)\n",
    "    \n",
    "    DG = nx.DiGraph(G) # bidirected version of G\n",
    "    df = gpd.read_file(\"../data/\"+level+\"/shape_files/\"+state+\"_\"+level+\".shp\")\n",
    "\n",
    "    # set parameters\n",
    "    k = number_of_congressional_districts[state]        \n",
    "    population = {node : G.nodes[node]['POP100'] for node in G.nodes()}  \n",
    "    deviation = .2\n",
    "    L = math.ceil((1-deviation/2)*sum(population[node] for node in G.nodes())/k)\n",
    "    U = math.floor((1+deviation/2)*sum(population[node] for node in G.nodes())/k)\n",
    "    print(\"L =\",L,\", U =\",U,\", k =\",k)\n",
    "    result['k'] = k\n",
    "    result['L'] = L\n",
    "    result['U'] = U\n",
    "    result['m'] = G.number_of_edges()\n",
    "    result['n'] = G.number_of_nodes()\n",
    "    \n",
    "    # abort early for trivial or overtly infeasible instances\n",
    "    maxp = max(population[i] for i in G.nodes)\n",
    "    if k==1 or maxp>U:\n",
    "        print(\"k=\",k,\", max{ p_v | v in V } =\",maxp,\", U =\",U,end='.')\n",
    "        sys.exit(\"Aborting early, either due to trivial instance or overtly infeasible instance.\")\n",
    "           \n",
    "    # read heuristic solution from external file (?)\n",
    "    heuristic = config['heuristic']\n",
    "    result['heur_obj'] = 'n/a'\n",
    "    result['heur_time'] = 'n/a'\n",
    "    result['heur_iter'] = 'n/a'\n",
    "        \n",
    "          \n",
    "    ############################\n",
    "    # Build base model\n",
    "    ############################   \n",
    "    \n",
    "    m = gp.Model()\n",
    "    m._DG = DG\n",
    "    base = config['base']\n",
    "    \n",
    "    if base == 'hess':\n",
    "        # X[i,j]=1 if vertex i is assigned to (district centered at) vertex j\n",
    "        m._X = m.addVars(DG.nodes, DG.nodes, vtype=GRB.BINARY)\n",
    "        hess.add_base_constraints(m, population, L, U, k)\n",
    "    \n",
    "    if base == 'labeling':        \n",
    "        # X[i,j]=1 if vertex i is assigned to district j in {0,1,2,...,k-1}\n",
    "        m._X = m.addVars(DG.nodes, range(k), vtype=GRB.BINARY, name=\"X\")\n",
    "        if config['symmetry']=='orbitope' or config['contiguity'] in {'scf', 'shir', 'lcut'}:\n",
    "            m._R = m.addVars(DG.nodes, range(k), vtype=GRB.BINARY)\n",
    "        labeling.add_base_constraints(m, population, L, U, k)\n",
    "\n",
    "                \n",
    "    ############################################\n",
    "    # Add (extended?) objective \n",
    "    ############################################\n",
    "    \n",
    "    extended = config['extended']\n",
    "    obj = config['obj']\n",
    "    \n",
    "    if base == 'hess':\n",
    "        if extended:\n",
    "            hess.add_extended_objective(m, G)\n",
    "        else:\n",
    "            hess.add_objective(m, G)\n",
    "    print(config)\n",
    "    \n",
    "    R=config['R']\n",
    "    \n",
    "    dist_bounds = config[\"dist_bounds\"]\n",
    "    if base == 'labeling':\n",
    "        # if extended:\n",
    "        #     labeling.add_extended_objective(m, G, k)`\n",
    "        # else:\n",
    "        #     labeling.add_objective(m, G, k)\n",
    "        if obj == \"PWL\":\n",
    "            labeling.add_PWL_objective(m, G, k, R)\n",
    "            if heuristic:\n",
    "                heuristic_districts = [ [node  for node in G.nodes  if G.nodes[node]['start_bvap']==j+1] for j in range(k) ]\n",
    "            else:\n",
    "                heuristic_districts = None\n",
    "        elif obj == \"step-exp\":\n",
    "            (expErr,maxErr) = labeling.add_step_exp_objective(m, G, k, R)\n",
    "            if heuristic:\n",
    "                heuristic_districts = [ [node  for node in G.nodes  if G.nodes[node]['start_bvap']==j+1] for j in range(k) ]\n",
    "            else:\n",
    "                heuristic_districts = None\n",
    "        elif obj == \"step-max\":\n",
    "            (expErr,maxErr) = labeling.add_step_max_objective(m, G, k, R)\n",
    "            if heuristic:\n",
    "                heuristic_districts = [ [node  for node in G.nodes  if G.nodes[node]['start_bvap']==j+1] for j in range(k) ]\n",
    "            else:\n",
    "                heuristic_districts = None\n",
    "        elif obj == \"cumulative\":\n",
    "            labeling.add_cumulative_objective(m, G, k)\n",
    "        elif obj == \"conv\":\n",
    "            labeling.add_conv_objective(m, G, k, dist_bounds)\n",
    "            if heuristic:\n",
    "                heuristic_districts = [ [node  for node in G.nodes  if G.nodes[node]['start_bvap']==j+1] for j in range(k) ]\n",
    "            else:\n",
    "                heuristic_districts = None\n",
    "        elif obj ==\"conv_approx\":\n",
    "            labeling.add_conv_approx_objective(m, G, k)\n",
    "            if heuristic:\n",
    "                heuristic_districts = [ [node  for node in G.nodes  if G.nodes[node]['start_bvap']==j+1] for j in range(k) ]\n",
    "            else:\n",
    "                heuristic_districts = None\n",
    "        elif obj ==\"PWL_approx\":\n",
    "            labeling.add_PWL_approx_objective(m, G, k, R)\n",
    "            if heuristic:\n",
    "                heuristic_districts = [ [node  for node in G.nodes  if G.nodes[node]['start_bvap']==j+1] for j in range(k) ]\n",
    "            else:\n",
    "                heuristic_districts = None\n",
    "        elif obj ==\"partisan_dem\":\n",
    "            labeling.add_partisan_dem_objective(m, G, k, R,U)\n",
    "            if heuristic:\n",
    "                heuristic_districts = [ [node  for node in G.nodes  if G.nodes[node]['start_dem']==j+1] for j in range(k) ]\n",
    "            else:\n",
    "                heuristic_districts = None\n",
    "        elif obj ==\"partisan_dem_order\":\n",
    "            labeling.add_partisan_dem_objective_ordering(m, G, k, R,U,config['obj_order'],config['index'] )\n",
    "            if heuristic:\n",
    "                heuristic_districts = [ [node  for node in G.nodes  if G.nodes[node]['start_dem']==j+1] for j in range(k) ]\n",
    "            else:\n",
    "                heuristic_districts = None\n",
    "        elif obj ==\"partisan_rep\":\n",
    "            labeling.add_partisan_rep_objective(m, G, k, R,U)\n",
    "            if heuristic:\n",
    "                heuristic_districts = [ [node  for node in G.nodes  if G.nodes[node]['start_rep']==j+1] for j in range(k) ]\n",
    "            else:\n",
    "                heuristic_districts = None\n",
    "        elif obj ==\"competetive\":\n",
    "            labeling.add_comp_objective(m, G, k)\n",
    "            if heuristic:\n",
    "                heuristic_districts = [ [node  for node in G.nodes  if G.nodes[node]['start_comp']==j+1] for j in range(k) ]\n",
    "            else:\n",
    "                heuristic_districts = None\n",
    "        elif obj == \"step-ordered\":\n",
    "            labeling.add_step_ordered_objective(m, G, k, R,U)\n",
    "            if heuristic:\n",
    "                heuristic_districts = [ [node  for node in G.nodes  if G.nodes[node]['start_bvap']==j+1] for j in range(k) ]\n",
    "            else:\n",
    "                heuristic_districts = None\n",
    "        elif obj == \"DiscretePWL\":\n",
    "            labeling.add_disctrete_PWL_objective(m, G, k, R)\n",
    "            if heuristic:\n",
    "                heuristic_districts = [ [node  for node in G.nodes  if G.nodes[node]['start_bvap']==j+1] for j in range(k) ]\n",
    "            else:\n",
    "                heuristic_districts = None\n",
    "        elif obj == \"step-alt\":\n",
    "            (expErr,maxErr) = labeling.add_step_alt_objective(m, G, k, R)\n",
    "            if heuristic:\n",
    "                heuristic_districts = [ [node  for node in G.nodes  if G.nodes[node]['start_bvap']==j+1] for j in range(k) ]\n",
    "            else:\n",
    "                heuristic_districts = None\n",
    "        elif obj == \"step-hvap\":\n",
    "            labeling.add_step_hvap_objective(m, G, k, R, state)\n",
    "            if heuristic:\n",
    "                heuristic_districts = [ [node  for node in G.nodes  if G.nodes[node]['start_bvap']==j+1] for j in range(k) ]\n",
    "            else:\n",
    "                heuristic_districts = None\n",
    "        elif obj == \"compact\":\n",
    "            labeling.add_compact_objective2(m, G, k, R, state)\n",
    "            if heuristic:\n",
    "                heuristic_districts = [ [node  for node in G.nodes  if G.nodes[node]['start_bvap']==j+1] for j in range(k) ]\n",
    "            else:\n",
    "                heuristic_districts = None\n",
    "        elif obj == \"perimax\":\n",
    "            labeling.add_perimax_objective(m, G, k)\n",
    "            if heuristic:\n",
    "                heuristic_districts = [ [node  for node in G.nodes  if G.nodes[node]['start_bvap']==j+1] for j in range(k) ]\n",
    "            else:\n",
    "                heuristic_districts = None\n",
    "        elif obj == \"perimin\":\n",
    "            labeling.add_perimin_objective(m, G, k)\n",
    "            if heuristic:\n",
    "                heuristic_districts = [ [node  for node in G.nodes  if G.nodes[node]['start_bvap']==j+1] for j in range(k) ]\n",
    "            else:\n",
    "                heuristic_districts = None\n",
    "        elif obj == \"BNPWL\":\n",
    "            labeling.add_BNPWL_objective(m, G, k, R,U)\n",
    "            if heuristic:\n",
    "                heuristic_districts = [ [node  for node in G.nodes  if G.nodes[node]['start_bvap']==j+1] for j in range(k) ]\n",
    "            else:\n",
    "                heuristic_districts = None\n",
    "        elif obj == \"LogEPWL\":\n",
    "            labeling.add_LogEPWL_objective(m, G, k, R, U)\n",
    "            if heuristic:\n",
    "                heuristic_districts = [ [node  for node in G.nodes  if G.nodes[node]['start_bvap']==j+1] for j in range(k) ]\n",
    "            else:\n",
    "                heuristic_districts = None\n",
    "                \n",
    "        elif obj == \"bounds\":\n",
    "            \n",
    "            labeling.add_LogEPWL_objective(m, G, k, R)\n",
    "            if heuristic:\n",
    "                heuristic_districts = [ [node  for node in G.nodes  if G.nodes[node]['start_bvap']==j+1] for j in range(k) ]\n",
    "            else:\n",
    "                heuristic_districts = None\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ####################################   \n",
    "    # Contiguity constraints\n",
    "    ####################################      \n",
    "            \n",
    "    contiguity = config['contiguity']\n",
    "    m._callback = None\n",
    "    m._population = population\n",
    "    m._U = U\n",
    "    m._k = k\n",
    "    m._base = base\n",
    "    m._numLazyCuts = 0\n",
    "    m._numCallbacks = 0\n",
    "    \n",
    "    if base == 'hess':\n",
    "        if contiguity == 'shir':\n",
    "            hess.add_shir_constraints(m)\n",
    "        elif contiguity == 'scf':\n",
    "            hess.add_scf_constraints(m, G, extended)\n",
    "        elif contiguity == 'lcut':\n",
    "            m.Params.lazyConstraints = 1\n",
    "            m._callback = separation.lcut_separation_generic\n",
    "                    \n",
    "    if base == 'labeling':\n",
    "        if contiguity == 'shir':\n",
    "            labeling.add_shir_constraints(m, config['symmetry'])\n",
    "        elif contiguity == 'scf':\n",
    "            labeling.add_scf_constraints(m, G, extended, config['symmetry'])\n",
    "        elif contiguity == 'lcut':\n",
    "            m.Params.lazyConstraints = 1\n",
    "            m._callback = separation.lcut_separation_generic \n",
    "    \n",
    "    \n",
    "    m.update()\n",
    "    \n",
    "    \n",
    "    ############################################\n",
    "    # Vertex ordering and max B problem \n",
    "    ############################################  \n",
    "        \n",
    "#     order = config['order']\n",
    "    \n",
    "#     if order == 'B_decreasing':\n",
    "#         (B, result['B_q'], result['B_time'], result['B_timelimit']) = ordering.solve_maxB_problem(DG, population, L, k, heuristic_districts)\n",
    "        \n",
    "#         # draw set B on map and save\n",
    "#         fn_B = \"../\" + \"results_for_\" + config_filename_wo_extension + \"/\" + result['state'] + \"-\" + result['level'] + \"-maxB.png\"       \n",
    "#         export_B_to_png(G, df, B, fn_B)\n",
    "#     else:\n",
    "#         (B, result['B_q'], result['B_time'], result['B_timelimit']) = (list(),'n/a','n/a', 'n/a')\n",
    "        \n",
    "#     result['B_size'] = len(B)\n",
    "    \n",
    "#     vertex_ordering = ordering.find_ordering(order, B, DG, population)\n",
    "#     position = ordering.construct_position(vertex_ordering)\n",
    "    \n",
    "#     print(\"Vertex ordering =\", vertex_ordering)  \n",
    "#     print(\"Position vector =\", position)\n",
    "#     print(\"Set B =\", B)\n",
    "\n",
    "    ####################################   \n",
    "    # Symmetry handling\n",
    "    ####################################    \n",
    "    \n",
    "    symmetry = config['symmetry']\n",
    "    \n",
    "    if symmetry == 'aggressive':\n",
    "        m.Params.symmetry = 2\n",
    "    elif symmetry == 'orbitope':\n",
    "        if base == 'labeling':\n",
    "            labeling.add_orbitope_extended_formulation(m, G, k, vertex_ordering)\n",
    "        else:\n",
    "            sys.exit(\"Error: orbitope only available for labeling base model.\")     \n",
    "    \n",
    "    m.Params.symmetry = 0\n",
    "            \n",
    "    ####################################   \n",
    "    # Variable fixing\n",
    "    ####################################    \n",
    "    \n",
    "    do_fixing = config['fixing']\n",
    "    \n",
    "    if do_fixing and base == 'hess':\n",
    "        result['DFixings'] = fixing.do_Hess_DFixing(m, G, position)\n",
    "        result['UFixings_R'] = 'n/a'\n",
    "        \n",
    "        if contiguity == 'none':\n",
    "            result['LFixings'] = fixing.do_Hess_LFixing_without_Contiguity(m, G, population, L, vertex_ordering)\n",
    "            result['UFixings_X'] = fixing.do_Hess_UFixing_without_Contiguity(m, G, population, U)\n",
    "        else:\n",
    "            result['LFixings'] = fixing.do_Hess_LFixing(m, G, population, L, vertex_ordering)\n",
    "            result['UFixings_X'] = fixing.do_Hess_UFixing(m, DG, population, U, vertex_ordering)         \n",
    "        \n",
    "        if extended:\n",
    "            result['ZFixings'] = fixing.do_Hess_ZFixing(m, G)\n",
    "        else:\n",
    "            result['ZFixings'] = 0\n",
    "                \n",
    "    \n",
    "    if do_fixing and base == 'labeling':\n",
    "        #result['DFixings'] = fixing.do_Labeling_DFixing(m, G, vertex_ordering, k)\n",
    "        \n",
    "        if contiguity == 'none':\n",
    "            if symmetry == 'orbitope':\n",
    "                1\n",
    "                #result['LFixings'] = fixing.do_Labeling_LFixing_without_Contiguity(m, G, population, L, vertex_ordering, k)\n",
    "            else:\n",
    "                result['LFixings'] = 0\n",
    "            (result['UFixings_X'], result['UFixings_R']) = fixing.do_labeling_UFixing_without_Contiguity()\n",
    "        #else:\n",
    "            #result['LFixings'] = fixing.do_Labeling_LFixing(m, G, population, L, vertex_ordering, k)\n",
    "            #(result['UFixings_X'], result['UFixings_R']) = fixing.do_Labeling_UFixing(m, DG, population, U, vertex_ordering, k)\n",
    "        \n",
    "        if extended:\n",
    "            result['ZFixings'] = fixing.do_Labeling_ZFixing(m, G, k)\n",
    "        else:\n",
    "            result['ZFixings'] = 0\n",
    "            \n",
    "    if not do_fixing:\n",
    "        result['DFixings'] = 0\n",
    "        result['UFixings_R'] = 0\n",
    "        result['LFixings'] = 0\n",
    "        result['UFixings_X'] = 0\n",
    "        result['ZFixings'] = 0\n",
    "            \n",
    "    \n",
    "    ######################################################################################\n",
    "    # Solve root LP? Used only for reporting purposes. Not used for MIP solve.\n",
    "    ######################################################################################  \n",
    "    \n",
    "    if config['lp']:\n",
    "        r = m.relax() # LP relaxation of MIP model m\n",
    "        r.Params.LogToConsole = 0 # keep log to a minimum\n",
    "        r.Params.Method = 3 # use concurrent LP solver\n",
    "        r.Params.TimeLimit = 3600 # one-hour time limit for solving LP\n",
    "        print(\"To get the root LP bound, now solving a (separate) LP model.\")\n",
    "        \n",
    "        lp_start = time.time()\n",
    "        r.optimize()\n",
    "        lp_end = time.time()\n",
    "        \n",
    "        if r.status == GRB.OPTIMAL:\n",
    "            result['LP_obj'] = '{0:.2f}'.format(r.objVal)\n",
    "        elif r.status == GRB.TIME_LIMIT:\n",
    "            result['LP_obj'] = 'TL'\n",
    "        else:\n",
    "            result['LP_obj'] = '?'\n",
    "        result['LP_time'] = '{0:.2f}'.format(lp_end - lp_start)\n",
    "        \n",
    "    else:\n",
    "        result['LP_obj'] = 'n/a'\n",
    "        result['LP_time'] = 'n/a'\n",
    "        \n",
    "    \n",
    "    ####################################   \n",
    "    # Inject heuristic warm start\n",
    "    ####################################    \n",
    "    \n",
    "    if heuristic and base == 'hess':\n",
    "        for district in heuristic_districts:    \n",
    "            p = min([position[v] for v in district])\n",
    "            j = vertex_ordering[p]\n",
    "            for i in district:\n",
    "                m._X[i,j].start = 1\n",
    "               \n",
    "    print(\"\\n start stuff \\n\")            \n",
    "    if heuristic and base == 'labeling':\n",
    "        print('skip ordered sol add')\n",
    "        #m.read(\"ordering test_44_reordered.sol\");\n",
    "        \n",
    "        # m.update();\n",
    "#         flag = 0\n",
    "#         for i in G.nodes:\n",
    "#             count = 0\n",
    "#             for nodes in heuristic_districts:\n",
    "#                 if i in nodes:\n",
    "#                     count = count+1\n",
    "#             if count != 1:\n",
    "#                 print(i, count)\n",
    "#                 flag = 1\n",
    "#         if flag:\n",
    "#             print(\"Error\")\n",
    "                \n",
    "            \n",
    "                \n",
    "#         for i,nodes in enumerate(heuristic_districts):\n",
    "#             for node in nodes:\n",
    "#                 m._X[node,i].start = int(1)\n",
    "                \n",
    "#                 for j in range(k):\n",
    "#                     if i != j:\n",
    "#                         m._X[node,j].start = 0\n",
    "        \n",
    "#         center_positions = [ min( position[v] for v in heuristic_districts[j] ) for j in range(k) ] \n",
    "#         cplabel = { center_positions[j] : j for j in range(k) }\n",
    "    \n",
    "#         # what node r will root the new district j? The one with earliest position.\n",
    "#         for j in range(k):\n",
    "#             min_cp = min(center_positions)\n",
    "#             r = vertex_ordering[min_cp]\n",
    "#             old_j = cplabel[min_cp]\n",
    "            \n",
    "#             for i in heuristic_districts[old_j]:\n",
    "#                 m._X[i,j].start = 1\n",
    "                \n",
    "#             center_positions.remove(min_cp)\n",
    "                \n",
    "    \n",
    "    ####################################   \n",
    "    # Solve MIP\n",
    "    ####################################  \n",
    "    \n",
    "    result['MIP_timelimit'] = config['tlimit'] \n",
    "    m.Params.TimeLimit = result['MIP_timelimit']\n",
    "    m.Params.Method = 3 # use concurrent method for root LP. Useful for degenerate models\n",
    "    \n",
    "    fn = \"../\" + \"results_for_\" + config_filename_wo_extension + \"/\" + result['state'] + \"-\" + result['level'] + \"-\" + config['obj'] + \"-\" + str(config['R'])\n",
    "    m.params.LogFile= fn+\".log\"\n",
    "    \n",
    "    \n",
    "    #zz = m.addVar(vtype = GRB.INTEGER,name = 'z' )\n",
    "    #zzz = m.addVar(vtype = GRB.INTEGER,name = 'zzz', lb = 0, ub = 4 )\n",
    "    \n",
    "    #best_district = [0, 2, 34, 4, 35, 36, 9, 44, 14, 16, 17, 19, 21, 27, 28, 30]\n",
    "    #m.addConstr(4*zz == gp.quicksum(m._X[i,6] for i in best_district) + zzz)\n",
    "    #zz.branchPriority = 0\n",
    "    #next_best = [1, 15, 22, 23, 33, 39]\n",
    "    #m.addConstr(gp.quicksum(m._X[i,6] for i in best_district)>= 10)\n",
    "    #m.addConstr(gp.quicksum(m._X[i,5] for i in next_best)>= 4)\n",
    "    #m.setParam('LogToConsole', 0)\n",
    "    m.write(\"this_optimization_model.lp\")\n",
    "    start = time.time()\n",
    "    m.optimize(m._callback)\n",
    "    end = time.time()\n",
    "    result['MIP_time'] = '{0:.2f}'.format(end-start)\n",
    "    \n",
    "    result['MIP_status'] = int(m.status)\n",
    "    result['MIP_nodes'] = int(m.NodeCount)\n",
    "    result['MIP_bound'] = m.objBound\n",
    "    result['callbacks'] = m._numCallbacks\n",
    "    result['lazy_cuts'] = m._numLazyCuts\n",
    "    if obj == \"step-exp\" or obj == \"step-max\":\n",
    "        result['expected_error'] = expErr\n",
    "        result['maximum_error'] = maxErr\n",
    "    \n",
    "    # report best solution found\n",
    "    if m.SolCount > 0:\n",
    "        result['MIP_obj'] = m.objVal\n",
    "\n",
    "        if base == 'hess':\n",
    "            labels = [ j for j in DG.nodes if m._X[j,j].x > 0.5 ]\n",
    "        else: # base == 'labeling'\n",
    "            labels = [ j for j in range(k) ]\n",
    "            \n",
    "        districts = [ [ i for i in DG.nodes if m._X[i,j].x > 0.5 ] for j in labels]\n",
    "        print(\"best solution (found) =\",districts)\n",
    "        \n",
    "        # export solution to .json file\n",
    "        m.write(fn+'.sol')\n",
    "        json_fn = fn + \".json\"\n",
    "        export_to_json(G, districts, json_fn)\n",
    "        \n",
    "        # export solution to .png file (districting map)\n",
    "        png_fn = fn + \".png\"\n",
    "        export_to_png(G, df, districts, png_fn)\n",
    "        \n",
    "        # is solution connected?\n",
    "        connected = True\n",
    "        for district in districts:\n",
    "            if not nx.is_connected(G.subgraph(district)):\n",
    "                connected = False\n",
    "        result['connected'] = connected\n",
    "        \n",
    "    else:\n",
    "        result['MIP_obj'] = 'no_solution_found'\n",
    "        result['connected'] = 'n/a'\n",
    "        \n",
    "            \n",
    "    ####################################   \n",
    "    # Summarize results of this run to csv file\n",
    "    ####################################  \n",
    "    for name in list(result.keys()):\n",
    "        if name not in my_fieldnames:\n",
    "            my_fieldnames.append(name)\n",
    "    append_dict_as_row(results_filename,result,my_fieldnames)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': 'SC',\n",
       " 'level': 'county',\n",
       " 'base': 'labeling',\n",
       " 'obj': 'partisan_dem_order',\n",
       " 'R': 90,\n",
       " 'dist_bounds': False,\n",
       " 'tlimit': 60,\n",
       " 'fixing': False,\n",
       " 'contiguity': 'lcut',\n",
       " 'symmetry': 'default',\n",
       " 'extended': False,\n",
       " 'order': 'B_decreasing',\n",
       " 'heuristic': True,\n",
       " 'lp': False,\n",
       " 'obj_order': 'D20_max',\n",
       " 'index': 6,\n",
       " 'run': 'SC_dem_bounds6',\n",
       " 'k': 7,\n",
       " 'L': 658084,\n",
       " 'U': 804323,\n",
       " 'm': 109,\n",
       " 'n': 46,\n",
       " 'heur_obj': 'n/a',\n",
       " 'heur_time': 'n/a',\n",
       " 'heur_iter': 'n/a',\n",
       " 'DFixings': 0,\n",
       " 'UFixings_R': 0,\n",
       " 'LFixings': 0,\n",
       " 'UFixings_X': 0,\n",
       " 'ZFixings': 0,\n",
       " 'LP_obj': 'n/a',\n",
       " 'LP_time': 'n/a',\n",
       " 'MIP_timelimit': 60,\n",
       " 'MIP_time': '60.21',\n",
       " 'MIP_status': 9,\n",
       " 'MIP_nodes': 99925,\n",
       " 'MIP_bound': 246587.75947995664,\n",
       " 'callbacks': 85,\n",
       " 'lazy_cuts': 984,\n",
       " 'MIP_obj': 'no_solution_found',\n",
       " 'connected': 'n/a'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_fieldnames == list(result.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B_q\n",
      "B_size\n",
      "B_time\n",
      "B_timelimit\n",
      "expected_error\n",
      "maximum_error\n"
     ]
    }
   ],
   "source": [
    "for name in my_fieldnames:\n",
    "    if name not in list(result.keys()):\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj_order\n",
      "index\n"
     ]
    }
   ],
   "source": [
    "for name in list(result.keys()):\n",
    "    if name not in my_fieldnames:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Added ordering D20[j]   --> Slightly better, but still worse than original run.\n",
    "    0     0    6.97621    0  915          -    6.97621      -     -   53s\n",
    "     0     0    6.97600    0  913          -    6.97600      -     -   58s\n",
    "     0     0          -    0               -    6.97600      -     -   60s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  Added D[j] <= T[j] ---> Did worse!\n",
    "    0     0    6.97717    0  948    1.88990    6.97717   269%     -   46s\n",
    "     0     0    6.97690    0  932    1.88990    6.97690   269%     -   50s\n",
    "     0     0    6.97618    0  970    1.88990    6.97618   269%     -   56s\n",
    "     0     0          -    0         1.88990    6.97618   269%     -   60s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-6830bdf6b343>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-6830bdf6b343>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    Original Run 60 seconds (Dem objective SC)\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Original Run 60 seconds (Dem objective SC)\n",
    "0     0    6.97717    0  948    1.88990    6.97717   269%     -   46s\n",
    "     0     0    6.97690    0  932    1.88990    6.97690   269%     -   50s\n",
    "     0     0    6.97618    0  970    1.88990    6.97618   269%     -   56s\n",
    "     0     0    6.97563    0  967    1.88990    6.97563   269%     -   59s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed value of parameter LogFile to mylog.log\n",
      "   Prev: ../results_for_config-rob-tests-BNPWL/SC-county-LogEPWL-90.log  Default: \n"
     ]
    },
    {
     "ename": "GurobiError",
     "evalue": "Unknown file type for file 'mylog.log'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mGurobiError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-80280be231db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Set the LogFile parameter and write the log to a file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetParam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'LogFile'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'mylog.log'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mylog.log'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32msrc\\gurobipy\\model.pxi\u001b[0m in \u001b[0;36mgurobipy.Model.write\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mGurobiError\u001b[0m: Unknown file type for file 'mylog.log'"
     ]
    }
   ],
   "source": [
    "{0: {0: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64]\n",
    "  , 1: [65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89]}, \n",
    " 1: {0: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], 1: [33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89]}, \n",
    " 2: {0: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80], \n",
    "     1: [17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 81, 82, 83, 84, 85, 86, 87, 88, 89]}, \n",
    " 3: {0: [1, 2, 3, 4, 5, 6, 7, 8, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 89], \n",
    "     1: [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88]}, \n",
    " 4: {0: [1, 2, 3, 4, 13, 14, 15, 16, 17, 18, 19, 20, 29, 30, 31, 32, 33, 34, 35, 36, 45, 46, 47, 48, 49, 50, 51, 52, 61, 62, 63, 64, 65, 66, 67, 68, 77, 78, 79, 80, 81, 82, 83, 84], \n",
    "     1: [5, 6, 7, 8, 9, 10, 11, 12, 21, 22, 23, 24, 25, 26, 27, 28, 37, 38, 39, 40, 41, 42, 43, 44, 53, 54, 55, 56, 57, 58, 59, 60, 69, 70, 71, 72, 73, 74, 75, 76, 85, 86, 87, 88, 89]}, \n",
    " 5: {0: [1, 2, 7, 8, 9, 10, 15, 16, 17, 18, 23, 24, 25, 26, 31, 32, 33, 34, 39, 40, 41, 42, 47, 48, 49, 50, 55, 56, 57, 58, 63, 64, 65, 66, 71, 72, 73, 74, 79, 80, 81, 82, 87, 88, 89], \n",
    "     1: [3, 4, 5, 6, 11, 12, 13, 14, 19, 20, 21, 22, 27, 28, 29, 30, 35, 36, 37, 38, 43, 44, 45, 46, 51, 52, 53, 54, 59, 60, 61, 62, 67, 68, 69, 70, 75, 76, 77, 78, 83, 84, 85, 86]}, \n",
    " 6: {0: [1, 4, 5, 8, 9, 12, 13, 16, 17, 20, 21, 24, 25, 28, 29, 32, 33, 36, 37, 40, 41, 44, 45, 48, 49, 52, 53, 56, 57, 60, 61, 64, 65, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 89], \n",
    "     1: [2, 3, 6, 7, 10, 11, 14, 15, 18, 19, 22, 23, 26, 27, 30, 31, 34, 35, 38, 39, 42, 43, 46, 47, 50, 51, 54, 55, 58, 59, 62, 63, 66, 67, 70, 71, 74, 75, 78, 79, 82, 83, 86, 87]}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some value values for SC\n",
    "vap_lb = [501419,501419,501419,501419,501419,501419,503655]\n",
    "vap_ub = [655035,655035,655035,655035,655035,655035, 653780]\n",
    "\n",
    "bvap_ub = [137826, 149052, 163457, 185065, 216833, 254706, 304582]\n",
    "bvap_lb = [77028, 77028, 77028, 77028, 95428, 111127, 172777]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-271530.72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "721247.8652474474"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(bvap_ub[6]**2 + vap_ub[6]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "532466.1968181642"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(2.835202507540e+11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "532466.1968181642"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(bvap_lb[6]**2 + vap_lb[6]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "704461.5910778955"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(4.962661333040e+11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " 263533 163809    1.34901   63   46    1.33573    1.46075  9.36%  16.6   50s\n",
    " 280839 173326    1.33637   53   40    1.33573    1.45941  9.26%  17.0   55s\n",
    " 297310 181677    1.43720   43   70    1.33573    1.45761  9.12%  17.6   60s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../results_for_config-rob-tests-BNPWL/SC-county-LogEPWL-12'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = m.getVarByName('f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam[6,7,in] 0\n",
    "lam[6,7,out] 4.2334955521418255e-01\n",
    "lam[6,8,in] 5.5573493325975332e-01\n",
    "lam[6,8,out] 2.0915511526064023e-02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "l7out= m.getVarByName(f'lam[6,7,out]').x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "l8in = m.getVarByName(f'lam[6,8,in]').x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "l8out = m.getVarByName(f'lam[6,8,out]').x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999998"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l7out + l8in + l8out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gurobi.Var f[0] (value 0.039799453702341364)>\n",
      "<gurobi.Var f[1] (value 0.07359627072208957)>\n",
      "<gurobi.Var f[2] (value 0.07616226720690616)>\n",
      "<gurobi.Var f[3] (value 0.07884219387784674)>\n",
      "<gurobi.Var f[4] (value 0.08653958110047141)>\n",
      "<gurobi.Var f[5] (value 0.525263346654526)>\n",
      "<gurobi.Var f[6] (value 0.6105529590708061)>\n"
     ]
    }
   ],
   "source": [
    "for j in range(k):\n",
    "    print(m.getVarByName(f'f[{j}]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gurobi.Var y[0] (value 629679.0)>\n",
      "<gurobi.Var y[1] (value 537662.0)>\n",
      "<gurobi.Var y[2] (value 595591.0)>\n",
      "<gurobi.Var y[3] (value 583282.0)>\n",
      "<gurobi.Var y[4] (value 631354.0)>\n",
      "<gurobi.Var y[5] (value 517860.0)>\n",
      "<gurobi.Var y[6] (value 519040.0)>\n"
     ]
    }
   ],
   "source": [
    "for j in range(k):\n",
    "    print(m.getVarByName(f'y[{j}]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gurobi.Var z[0] (value 89262.0)>\n",
      "<gurobi.Var z[1] (value 92355.0)>\n",
      "<gurobi.Var z[2] (value 108679.0)>\n",
      "<gurobi.Var z[3] (value 109767.0)>\n",
      "<gurobi.Var z[4] (value 131180.0)>\n",
      "<gurobi.Var z[5] (value 217520.0)>\n",
      "<gurobi.Var z[6] (value 222581.0)>\n"
     ]
    }
   ],
   "source": [
    "for j in range(k):\n",
    "    print(m.getVarByName(f'z[{j}]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1417579433330316\n",
      "0.17177148468740583\n",
      "0.18247253568304422\n",
      "0.18818856059333222\n",
      "0.2077756694342635\n",
      "0.4200363032479821\n",
      "0.42883207459926015\n"
     ]
    }
   ],
   "source": [
    "for j in range(k):\n",
    "    print(m.getVarByName(f'z[{j}]').x/m.getVarByName(f'y[{j}]').x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03148804404064194, 0.039799453702341364]\n",
      "[0.04901421544200262, 0.07359627072208957]\n",
      "[0.05688845146909919, 0.07616226720690616]\n",
      "[0.06148518907470151, 0.07884219387784674]\n",
      "[0.07945850412978173, 0.08653958110047141]\n",
      "[0.5160203279901475, 0.525263346654526]\n",
      "[0.5399102998242208, 0.6105529590708061]\n"
     ]
    }
   ],
   "source": [
    "for j in range(k):\n",
    "    print([labeling.cdf_fun(m.getVarByName(f'z[{j}]').x/m.getVarByName(f'y[{j}]').x), m.getVarByName(f'f[{j}]').x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum((lam[d,i,'in']+lam[d,i,'out'])*f_bvap(B[i][1]/B[i][0]) for i in range(L)) for d in D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "51810 27489    1.53642   38  125    1.36246    1.74488  28.1%   135   56s\n",
    " 57410 30386    1.54474   39  118    1.36246    1.73821  27.6%   135   60s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf and sup ratios: 0.06407776152503185, 0.6846119336025124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6074400850386603"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "304582/501419"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1178194499678791"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "77028/653780"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ## population variables\n",
    "    vap_lb = [501419,501419,501419,501419,501419,501419,503655]\n",
    "    vap_ub = [655035,655035,655035,655035,655035,655035, 653780]\n",
    "    \n",
    "    vap = {j : m.addVar(name = f\"vap{j}\", ub = vap_ub[j], lb = vap_lb[j])   for j in range(k)} # voting age population in district j\n",
    "    \n",
    "    bvap_ub = [137826, 149052, 163457, 185065, 216833, 254706, 304582]\n",
    "    bvap_lb = [77028, 77028, 77028, 77028, 95428, 111127, 172777]\n",
    "    bvap = {j : m.addVar(name = f\"bvap{j}\", ub = bvap_ub[j], lb = 77028)  for j in range(k)} # bvap in district j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "674196"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "501419 + 172777"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precomputed bounds for each order + bvap ordering\n",
    " 129822 64495 infeasible   78               -    1.70667      -  71.7   55s\n",
    " 160374 79927    1.54167   53  112          -    1.69631      -  72.0   60s (slight improvement...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precomputed bounds + bvap ordering\n",
    " 56906 24123    1.57094   56  114          -    1.79019      -  72.6   45s\n",
    " 84444 34548 infeasible  102               -    1.74728      -  70.7   50s\n",
    " 115157 50956    1.28257   58   73          -    1.71752      -  67.0   56s\n",
    " 139810 62258 infeasible   76               -    1.70287      -  61.9   60s (Way better!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Precomputed bounds + objective ordering\n",
    " 2920  2485    2.17217   18  489    1.37979    2.17217  57.4%   111   50s\n",
    "  2976  2540    2.15457   45  449    1.37979    2.17005  57.3%   116   55s\n",
    "  3873  2841    1.46347   61  133    1.37979    2.17005  57.3%   154   60s (Slower!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adding precomputed upper and lower bounds on vap and bvap (no objective ordering)\n",
    " 32558 15733    1.99501   65  237    1.37979    2.08772  51.3%  74.0   50s\n",
    " 45220 22389    1.55480   89   56    1.37979    2.06289  49.5%  75.4   55s\n",
    " 58924 28984    1.79221   70  139    1.37979    2.04846  48.5%  76.0   60s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adding just upper bounds on Vap and also Vap >= bvap\n",
    "  2722  2255    1.72433   61  606    1.37979    2.45934  78.2%  47.1   50s\n",
    "  2738  2266    2.45765   25  602    1.37979    2.45765  78.1%  46.9   55s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fancy delta inequality\n",
    "2765  2398    2.38401   40  598    1.37979    2.52117  82.7%  86.8   50s\n",
    "  2781  2408    2.49282   13  601    1.37979    2.51811  82.5%  86.3   55s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no ordering\n",
    "3347  2738    2.50354   21  591    1.37979    2.50354  81.4%  52.0   45s\n",
    "  3363  2748    2.50061   22  585    1.37979    2.50061  81.2%  51.8   50s\n",
    "  3378  2758    2.49687   35  590    1.37979    2.49687  81.0%  51.6   55s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered cdf, but not deltas\n",
    "  2765  2253    1.61491   74  575    1.37979    2.47024  79.0%  67.9   50s\n",
    "  2785  2266    2.46641    8  588    1.37979    2.46641  78.8%  67.4   55s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  ordered deltas\n",
    "    2702  2244    2.52746   11  591    1.37979    2.52746  83.2%   100   50s\n",
    "  2715  2253    1.49713   73  580    1.37979    2.52575  83.1%  99.4   55s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2749  2242    2.07990   56  560    1.37979    2.46981  79.0%  68.3   45s\n",
    "  2768  2255    2.46172   15  583    1.37979    2.46172  78.4%  67.8   50s\n",
    "  2789  2269    2.45790   17  590    1.37979    2.45790  78.1%  67.3   55s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  2653  2142    2.50043   15  583    1.37979    2.50043  81.2%  43.8   40s\n",
    "  2672  2156    2.49879   12  488    1.37979    2.49879  81.1%  66.1   45s\n",
    "  2692  2169    2.48653   42  586    1.37979    2.48653  80.2%  65.6   50s\n",
    "  2708  2180    2.33831   16  606    1.37979    2.48365  80.0%  65.2   55s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(k):\n",
    "    print(m.getVarByName(f'cdf{j}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(k):\n",
    "    print(j, m.getVarByName(f'bvap{j}').x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bvap(dissolved,filename, additional_file_name = '', overlay = False, gdf2 = 0):\n",
    "        dissolved['Representative'] = dissolved['geometry'].apply(lambda x: x.representative_point().coords[:])\n",
    "        dissolved['Representative'] = [coords[0] for coords in dissolved['Representative']]\n",
    "        dissolved = dissolved.rename(columns={'P0010001':'POP','P0010004':'BPOP',\n",
    "                                                  'P0030001':'VAP','P0030004':'BVAP', 'P0040002' : 'HVAP'})\n",
    "        dissolved['BVAP_ratio'] = dissolved['BVAP']/dissolved['VAP']\n",
    "        colormap ='BuPu'\n",
    "        \n",
    "        fig, ax = plt.subplots(1,1, figsize=(16,16))\n",
    "        \n",
    "        cbax = fig.add_axes([0.95, 0.3, 0.03, 0.39])   \n",
    "        cbax.set_title(\"BVAP Ratio\")\n",
    "        vmin = 0\n",
    "        vmax = 0.75\n",
    "        sm = plt.cm.ScalarMappable(cmap=colormap, \\\n",
    "                norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "    \n",
    "        sm._A = []\n",
    "    \n",
    "        fig.colorbar(sm, cax=cbax)#, format=\"%d\")\n",
    "    \n",
    "        ax.axis(\"off\")\n",
    "\n",
    "        dissolved.plot(column = 'BVAP_ratio', edgecolor='black', cmap=colormap, ax = ax, vmin = vmin, vmax = vmax, legend=False)\n",
    "        #dissolved.apply(lambda x: \n",
    "             #ax.annotate(text=x.NAME, xy=x.Representative, ha='center', color = 'r',  weight='bold', size = 14), axis=1);\n",
    "        \n",
    "        #dissolved.set_index('my_index', inplace=True)\n",
    "        dissolved.reset_index(inplace=True)\n",
    "        #dissolved.apply(lambda x: \n",
    "             #ax.annotate(text=str(x.name) +': '+ str(x.BVAP), xy=x.Representative, ha='center', color = 'r',  weight='bold', size = 14), axis=1);\n",
    "        \n",
    "        dissolved.apply(lambda x: \n",
    "             ax.annotate(text=str(x.name) +': '+ str(round(labeling.cdf_fun(x.BVAP_ratio),2)), xy=x.Representative, ha='center', color = 'r',  weight='bold', size = 14), axis=1);\n",
    "        \n",
    "        if overlay:\n",
    "            gdf2.plot(ax=ax, edgecolor='blue', linewidth=2, facecolor='none')\n",
    "        plt.savefig(filename.split(\".\")[0] + '_BVAP' + additional_file_name + '.png', transparent=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeling.cdf_fun(int(G.nodes[42]['BVAP'])/int(G.nodes[42]['VAP']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89262.0 629679.0 0.1417579433330316\n",
      "92355.0 537662.0 0.17177148468740583\n",
      "108679.0 595591.0 0.18247253568304422\n",
      "109767.0 583282.0 0.18818856059333222\n",
      "131180.0 631354.0 0.2077756694342635\n",
      "217520.0 517860.0 0.4200363032479821\n",
      "222581.0 519040.0 0.42883207459926015\n"
     ]
    }
   ],
   "source": [
    "for j in range(k):\n",
    "    print(m.getVarByName(f'bvap{j}').x, m.getVarByName(f'vap{j}').x, m.getVarByName(f'bvap{j}').x/m.getVarByName(f'vap{j}').x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    vap_lb = [501419,501419,501419,501419,501419,501419,503655]\n",
    "    vap_ub = [655035,655035,655035,655035,655035,655035, 653780]\n",
    "    \n",
    "    bvap_ub = [137826, 149052, 163457, 185065, 216833, 254706, 304582]\n",
    "    bvap_lb = [77028, 77028, 77028, 77028, 95428, 111127, 172777]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(k):\n",
    "    print(m.getVarByName(f'cdf{j}').x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " 2585  2155    1.69849   65  484    1.37979    2.79425   103%  36.8   15s\n",
    "  2617  2176    2.77176   24  500    1.37979    2.77176   101%  36.3   20s\n",
    "  2643  2193    2.76157   34  531    1.37979    2.76157   100%  36.0   25s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dissolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.nodes[0]['VAP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['P0030004'][0] df['P0030001'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['P0030001'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
